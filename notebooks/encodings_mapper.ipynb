{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['image.interpolation'] = 'nearest'\n",
    "mpl.rcParams['figure.figsize'] = 15, 25\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingsDataset():\n",
    "    def __init__(self, artifact_dir, model_file, view, kind):\n",
    "        self.artifact_dir = artifact_dir\n",
    "        self.view = view\n",
    "        self.camera_images_dir = os.path.join(artifact_dir, 'data', 'camera_data', kind)\n",
    "        self.parts_images_dir = os.path.join(artifact_dir, 'data', 'parts_data', kind)\n",
    "\n",
    "        self.model_dir = os.path.join(artifact_dir, 'models')\n",
    "        self.model_path = os.path.join(self.model_dir, model_file)\n",
    "\n",
    "        self.camera_image_names = _get_camera_images_by_view(self.camera_images_dir, view)\n",
    "        self.parts_image_names = _get_camera_images_by_view(self.parts_images_dir, view)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        camera_image_path = os.path.join(self.camera_images_dir, self.camera_image_names[idx])\n",
    "        parts_image_path = os.path.join(self.parts_images_dir, self.camera_image_names[idx])\n",
    "        model_path = os.path.join(self.model_dir, '')\n",
    "\n",
    "        camera_image = Image.open(camera_image_path).convert('RGB')\n",
    "        camera_image = torchvision.transforms.functional.to_tensor(camera_image) \n",
    "        camera_image = camera_image.view(1, *parts_image.shape)\n",
    "\n",
    "        parts_image = Image.open(parts_image_path).convert('RGB')\n",
    "        parts_image = torchvision.transforms.functional.to_tensor(parts_image)\n",
    "        parts_image = parts_image.view(1, *parts_image.shape)\n",
    "\n",
    "        encoder_model = torch.load(self.model_path).encoder\n",
    "        part_encoding = encoder_model(parts_image)\n",
    "\n",
    "        return camera_image, part_encoding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.camera_image_names)\n",
    "\n",
    "    def _get_camera_images_by_view(path, view):\n",
    "        images = list(sorted(os.listdir(path)))\n",
    "        l = map(lambda name: name.split('.')[0], images)\n",
    "        l = list(sorted(list(filter(lambda name: name.endswith(view), l))))\n",
    "        return l\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda5256b649568d47b0ada5f4982042f9e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}